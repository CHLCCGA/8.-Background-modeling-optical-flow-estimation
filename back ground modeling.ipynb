{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frame difference method\n",
    "\n",
    "Since the target in the scene is moving, the position of the target image in different image frames is different. This type of algorithm performs a differential operation on two consecutive frames of images in time. The pixels corresponding to different frames are subtracted to determine the absolute value of the grayscale difference. When the absolute value exceeds a certain threshold, it can be determined to be a moving target, thereby achieving the goal. detection function.\n",
    "The frame difference method is very simple, but it will introduce noise and hole problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](bg_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian mixture model\n",
    "\n",
    "Before foreground detection, the background is trained first, and a Gaussian mixture model is used to simulate each background in the image. The number of Gaussian mixtures for each background can be adaptive. Then in the testing phase, GMM matching is performed on the new pixels. If the pixel value can match one of the Gaussians, it is considered to be the background, otherwise it is considered to be the foreground. Since the GMM model is continuously updated and learned throughout the process, it has a certain degree of robustness to dynamic backgrounds. Finally, good results were achieved by performing foreground detection on a dynamic background with swaying branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](bg_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual distribution of the background should be a mixture of multiple Gaussian distributions, and each Gaussian model can also have weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](bg_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixed Gaussian model learning method\n",
    "\n",
    "- 1. First initialize each Gaussian model matrix parameter.\n",
    "\n",
    "- 2. Take T frame data images from the video to train the Gaussian mixture model. After getting the first pixel, use it as the first Gaussian distribution.\n",
    "\n",
    "- 3. When the subsequent pixel value is compared with the mean value of the previous Gaussian, if the value of the pixel is within 3 times the variance of its model mean, it belongs to the distribution, and its parameters are updated.\n",
    "\n",
    "- 4. If the next coming pixel does not satisfy the current Gaussian distribution, use it to create a new Gaussian distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixed Gaussian model testing method\n",
    "\n",
    "In the testing phase, the value of the new pixel is compared with each mean value in the Gaussian mixture model. If the difference is between 2 times the variance, it is considered to be the background, otherwise it is considered to be the foreground. Assign the foreground value to 255 and the background value to 0. This forms a foreground binary image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](bg_5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#测试视频\n",
    "cap = cv2.VideoCapture('test.avi')\n",
    "#形态学操作\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "#混合高斯模型用于背景建模\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    #形态学开运算去噪点\n",
    "    fgmask = cv2.morphologyEx(fgmask, cv2.MORPH_OPEN, kernel)\n",
    "    #寻找视频中的轮廓\n",
    "    im, contours, hierarchy = cv2.findContours(fgmask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for c in contours:\n",
    "        #计算各轮廓的周长\n",
    "        perimeter = cv2.arcLength(c,True)\n",
    "        if perimeter > 188:\n",
    "            #找到一个直矩形（不会旋转）\n",
    "            x,y,w,h = cv2.boundingRect(c)\n",
    "            #画出矩形\n",
    "            cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)    \n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('fgmask', fgmask)\n",
    "    k = cv2.waitKey(150) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
